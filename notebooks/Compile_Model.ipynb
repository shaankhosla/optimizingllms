{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BYX8hFgpIdWI"
   },
   "source": [
    "[Source](https://pytorch.org/blog/Accelerating-Hugging-Face-and-TIMM-models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SVKO80P9H7Iu"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install --pre torch --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SzcTSukfH7tk",
    "outputId": "033c8f4c-ad80-4668-ea43-445a18157d25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import time\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "slow_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "fast_model = torch.compile(slow_model)\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71feVreWJD16",
    "outputId": "be2f82e5-c446-4ba6-d46d-34e8ec2dcb2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16397953033447266\n",
      "0.1758866310119629\n",
      "0.1841731071472168\n",
      "0.16378402709960938\n",
      "0.1588287353515625\n",
      "0.16391873359680176\n",
      "0.14704632759094238\n",
      "0.14936327934265137\n",
      "0.16373395919799805\n",
      "0.14490866661071777\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    st_time = time.time()\n",
    "    output = slow_model(**encoded_input)\n",
    "    print(time.time() - st_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "K1iwKyWMJ-ru"
   },
   "source": [
    " The first run is slow and that’s because the model is being compiled. Subsequent runs will be faster so it’s common practice to warm up your model before you start benchmarking it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9HoKYEiIRwv",
    "outputId": "e10c45a7-7753-4439-a575-b9bc38032f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.198747873306274\n",
      "0.0909581184387207\n",
      "0.0881953239440918\n",
      "0.096771240234375\n",
      "0.08929443359375\n",
      "0.09436845779418945\n",
      "0.09152889251708984\n",
      "0.09056305885314941\n",
      "0.09667491912841797\n",
      "0.09199810028076172\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    st_time = time.time()\n",
    "    output = fast_model(**encoded_input)\n",
    "    print(time.time() - st_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdGv3SOxIwvR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
