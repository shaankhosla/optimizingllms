{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81GOWrTOG9UL"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/shaankhosla/optimizingllms/blob/main/notebooks/Quantization.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3tZuoc7DZ7dQ",
    "outputId": "1358bb60-9730-4d52-8149-7f87c4694f49"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git\n",
      "  Cloning https://github.com/huggingface/optimum-intel.git to /tmp/pip-install-7p4o7jz_/optimum-intel_27591dd88b30405cba8cabd8dbaba390\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/optimum-intel.git /tmp/pip-install-7p4o7jz_/optimum-intel_27591dd88b30405cba8cabd8dbaba390\n",
      "  Resolved https://github.com/huggingface/optimum-intel.git to commit 6a9b778115771c0972b7e66a3d0df88bc55d8ef0\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: optimum>=1.8.8 in /usr/local/lib/python3.10/dist-packages (from optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.9.0)\n",
      "Requirement already satisfied: transformers>=4.20.0 in /usr/local/lib/python3.10/dist-packages (from optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (4.30.2)\n",
      "Requirement already satisfied: datasets>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (2.13.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (0.1.99)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.10.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (0.20.3)\n",
      "Collecting neural-compressor>=2.2.0 (from optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git)\n",
      "  Downloading neural_compressor-2.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting onnx (from optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git)\n",
      "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime<1.15.0 (from optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git)\n",
      "  Downloading onnxruntime-1.14.1-cp310-cp310-manylinux_2_27_x86_64.whl (5.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.22.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (9.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (0.3.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (0.15.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (6.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.2.2)\n",
      "Collecting schema (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git)\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (9.0.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (5.9.5)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (8.4.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (4.7.0.72)\n",
      "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (0.7.2)\n",
      "Collecting deprecated>=1.2.13 (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (2.0.6)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.15.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.15.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.15.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.15.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.11.1)\n",
      "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from optimum>=1.8.8->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (3.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (0.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (4.6.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.14.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (2.0.12)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (3.4)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum>=1.8.8->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum>=1.8.8->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum>=1.8.8->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->optimum>=1.8.8->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->optimum>=1.8.8->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (16.0.6)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<1.15.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (2022.7.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (3.7.1)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema->neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (0.6.0.post1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (3.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<1.15.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets>=1.4.0->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->optimum>=1.8.8->optimum-intel[neural-compressor]@ git+https://github.com/huggingface/optimum-intel.git) (2.1.3)\n",
      "Installing collected packages: schema, onnx, deprecated, onnxruntime, neural-compressor\n",
      "Successfully installed deprecated-1.2.14 neural-compressor-2.2 onnx-1.14.0 onnxruntime-1.14.1 schema-0.7.5\n"
     ]
    }
   ],
   "source": [
    "!pip install \"optimum-intel[neural-compressor]\"@git+https://github.com/huggingface/optimum-intel.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BXbfQMrSQb-S"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering\n",
    "from neural_compressor.config import PostTrainingQuantConfig\n",
    "from optimum.intel import INCQuantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "66b4d720ab404285bb69e89cba934fc8",
      "22409a1cd60d4a9383a9b3fbd374811c",
      "3d38f9770aa54ad3b4601260643cbc71",
      "309ab64a267847119dbbf799bdba447c",
      "ae2b8f28b3974930a3712ed9eb57134d",
      "f7bcdae127f641d4a1a24d7dc30202d1",
      "55e7a12c4ffa4f3dbe19bf215bcc0988",
      "d5ad347f0d6d47788baddbd2b4445ff8",
      "4561aad7ee2345a1b2cc251ec48ce0f4",
      "65398f401c3744c6b1e966bbd0e2df03",
      "1d6326a77fcc48afb1b4c0e0b5835fc7",
      "58914e1d600c4c0596caae9c5551919b",
      "53015ea7396146868a3711557116a1b6",
      "d6ee4d366725466b81574e2a6c3e9594",
      "f741d07cfe5d47bf846a9d0a13f0fcde",
      "0c07640adbf04476aaaf8c49f432bd17",
      "efca087f19214f10b9e12c6c67668c39",
      "a8bd11df2df04571b4bac9ea9e2666d4",
      "d09fd22b974444e7938785f845f5463a",
      "56ab5284239e4acdaedfb020efa93166",
      "c60ec5df7e944201849b7dc91901d4d9",
      "f8c3f6f1b08e42af95ac5df813103911"
     ]
    },
    "id": "s_vEZFAkQd6U",
    "outputId": "52e9b2f5-ecb1-4fe3-ec75-2a3e3ecd8469"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66b4d720ab404285bb69e89cba934fc8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/597M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58914e1d600c4c0596caae9c5551919b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForQuestionAnswering: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForQuestionAnswering were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-07-04 22:56:31 [INFO] Start auto tuning.\n",
      "2023-07-04 22:56:31 [INFO] Execute the tuning process due to detect the evaluation function.\n",
      "2023-07-04 22:56:31 [INFO] Adaptor has 4 recipes.\n",
      "2023-07-04 22:56:31 [INFO] 0 recipes specified by user.\n",
      "2023-07-04 22:56:31 [INFO] 3 recipes require future tuning.\n",
      "2023-07-04 22:56:31 [INFO] *** Initialize auto tuning\n",
      "2023-07-04 22:56:31 [INFO] {\n",
      "2023-07-04 22:56:31 [INFO]     'PostTrainingQuantConfig': {\n",
      "2023-07-04 22:56:31 [INFO]         'AccuracyCriterion': {\n",
      "2023-07-04 22:56:31 [INFO]             'criterion': 'relative',\n",
      "2023-07-04 22:56:31 [INFO]             'higher_is_better': True,\n",
      "2023-07-04 22:56:31 [INFO]             'tolerable_loss': 0.01,\n",
      "2023-07-04 22:56:31 [INFO]             'absolute': None,\n",
      "2023-07-04 22:56:31 [INFO]             'keys': <bound method AccuracyCriterion.keys of <neural_compressor.config.AccuracyCriterion object at 0x7f697662a8f0>>,\n",
      "2023-07-04 22:56:31 [INFO]             'relative': 0.01\n",
      "2023-07-04 22:56:31 [INFO]         },\n",
      "2023-07-04 22:56:31 [INFO]         'approach': 'post_training_dynamic_quant',\n",
      "2023-07-04 22:56:31 [INFO]         'backend': 'default',\n",
      "2023-07-04 22:56:31 [INFO]         'calibration_sampling_size': [\n",
      "2023-07-04 22:56:31 [INFO]             100\n",
      "2023-07-04 22:56:31 [INFO]         ],\n",
      "2023-07-04 22:56:31 [INFO]         'device': 'cpu',\n",
      "2023-07-04 22:56:31 [INFO]         'diagnosis': False,\n",
      "2023-07-04 22:56:31 [INFO]         'domain': 'auto',\n",
      "2023-07-04 22:56:31 [INFO]         'example_inputs': None,\n",
      "2023-07-04 22:56:31 [INFO]         'excluded_precisions': [\n",
      "2023-07-04 22:56:31 [INFO]         ],\n",
      "2023-07-04 22:56:31 [INFO]         'framework': 'pytorch_fx',\n",
      "2023-07-04 22:56:31 [INFO]         'inputs': [\n",
      "2023-07-04 22:56:31 [INFO]         ],\n",
      "2023-07-04 22:56:31 [INFO]         'model_name': '',\n",
      "2023-07-04 22:56:31 [INFO]         'op_name_dict': None,\n",
      "2023-07-04 22:56:31 [INFO]         'op_type_dict': None,\n",
      "2023-07-04 22:56:31 [INFO]         'outputs': [\n",
      "2023-07-04 22:56:31 [INFO]         ],\n",
      "2023-07-04 22:56:31 [INFO]         'quant_format': 'default',\n",
      "2023-07-04 22:56:31 [INFO]         'quant_level': 'auto',\n",
      "2023-07-04 22:56:31 [INFO]         'recipes': {\n",
      "2023-07-04 22:56:31 [INFO]             'smooth_quant': False,\n",
      "2023-07-04 22:56:31 [INFO]             'smooth_quant_args': {\n",
      "2023-07-04 22:56:31 [INFO]             },\n",
      "2023-07-04 22:56:31 [INFO]             'fast_bias_correction': False,\n",
      "2023-07-04 22:56:31 [INFO]             'weight_correction': False,\n",
      "2023-07-04 22:56:31 [INFO]             'gemm_to_matmul': True,\n",
      "2023-07-04 22:56:31 [INFO]             'graph_optimization_level': None,\n",
      "2023-07-04 22:56:31 [INFO]             'first_conv_or_matmul_quantization': True,\n",
      "2023-07-04 22:56:31 [INFO]             'last_conv_or_matmul_quantization': True,\n",
      "2023-07-04 22:56:31 [INFO]             'pre_post_process_quantization': True,\n",
      "2023-07-04 22:56:31 [INFO]             'add_qdq_pair_to_weight': False,\n",
      "2023-07-04 22:56:31 [INFO]             'optypes_to_exclude_output_quant': [\n",
      "2023-07-04 22:56:31 [INFO]             ],\n",
      "2023-07-04 22:56:31 [INFO]             'dedicated_qdq_pair': False\n",
      "2023-07-04 22:56:31 [INFO]         },\n",
      "2023-07-04 22:56:31 [INFO]         'reduce_range': None,\n",
      "2023-07-04 22:56:31 [INFO]         'TuningCriterion': {\n",
      "2023-07-04 22:56:31 [INFO]             'max_trials': 100,\n",
      "2023-07-04 22:56:31 [INFO]             'objective': 'performance',\n",
      "2023-07-04 22:56:31 [INFO]             'strategy': 'basic',\n",
      "2023-07-04 22:56:31 [INFO]             'strategy_kwargs': None,\n",
      "2023-07-04 22:56:31 [INFO]             'timeout': 0\n",
      "2023-07-04 22:56:31 [INFO]         },\n",
      "2023-07-04 22:56:31 [INFO]         'use_bf16': True\n",
      "2023-07-04 22:56:31 [INFO]     }\n",
      "2023-07-04 22:56:31 [INFO] }\n",
      "2023-07-04 22:56:31 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "2023-07-04 22:56:32 [INFO] Attention Blocks: 0\n",
      "2023-07-04 22:56:32 [INFO] FFN Blocks: 0\n",
      "2023-07-04 22:56:32 [INFO] Pass query framework capability elapsed time: 671.94 ms\n",
      "2023-07-04 22:56:32 [INFO] Get FP32 model baseline.\n",
      "2023-07-04 22:56:32 [INFO] Save tuning history to /content/nc_workspace/2023-07-04_22-56-07/./history.snapshot.\n",
      "2023-07-04 22:56:32 [INFO] FP32 baseline is: [Accuracy: 1.0000, Duration (seconds): 0.0000]\n",
      "2023-07-04 22:56:32 [INFO] Quantize the model with default config.\n",
      "2023-07-04 22:56:32 [INFO] Fx trace of the entire model failed, We will conduct auto quantization\n",
      "2023-07-04 22:56:38 [INFO] |Mixed Precision Statistics|\n",
      "2023-07-04 22:56:38 [INFO] +-----------+-------+------+\n",
      "2023-07-04 22:56:38 [INFO] |  Op Type  | Total | INT8 |\n",
      "2023-07-04 22:56:38 [INFO] +-----------+-------+------+\n",
      "2023-07-04 22:56:38 [INFO] | Embedding |   3   |  3   |\n",
      "2023-07-04 22:56:38 [INFO] |   Linear  |  109  | 109  |\n",
      "2023-07-04 22:56:38 [INFO] +-----------+-------+------+\n",
      "2023-07-04 22:56:38 [INFO] Pass quantize model elapsed time: 6184.32 ms\n",
      "2023-07-04 22:56:38 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 1.0000|1.0000, Duration (seconds) (int8|fp32): 0.0000|0.0000], Best tune result is: [Accuracy: 1.0000, Duration (seconds): 0.0000]\n",
      "2023-07-04 22:56:38 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2023-07-04 22:56:38 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2023-07-04 22:56:38 [INFO] |     Info Type      | Baseline | Tune 1 result | Best tune result |\n",
      "2023-07-04 22:56:38 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2023-07-04 22:56:38 [INFO] |      Accuracy      | 1.0000   |    1.0000     |     1.0000       |\n",
      "2023-07-04 22:56:38 [INFO] | Duration (seconds) | 0.0000   |    0.0000     |     0.0000       |\n",
      "2023-07-04 22:56:38 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2023-07-04 22:56:38 [INFO] Save tuning history to /content/nc_workspace/2023-07-04_22-56-07/./history.snapshot.\n",
      "2023-07-04 22:56:38 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2023-07-04 22:56:38 [INFO] Save deploy yaml to /content/nc_workspace/2023-07-04_22-56-07/deploy.yaml\n",
      "Model weights saved to dynamic_quantization/pytorch_model.bin\n",
      "Configuration saved in dynamic_quantization/inc_config.json\n"
     ]
    }
   ],
   "source": [
    "model_name = \"allenai/longformer-base-4096\"\n",
    "\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    model_name, cache_dir=\"model_cache\"\n",
    ")\n",
    "save_dir = \"dynamic_quantization\"\n",
    "\n",
    "quantization_config = PostTrainingQuantConfig(approach=\"dynamic\")\n",
    "quantizer = INCQuantizer.from_pretrained(model)\n",
    "quantizer.quantize(quantization_config=quantization_config, save_directory=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ftNpWpzekAl",
    "outputId": "68122a61-a079-4b7d-d625-258dab28a9c1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "570M\tmodel_cache/\n"
     ]
    }
   ],
   "source": [
    "!du -sh model_cache/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-T_Tg_LemCE",
    "outputId": "9baa4b30-3b6d-4620-ff5d-0037c7e0e297"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "145M\tdynamic_quantization/\n"
     ]
    }
   ],
   "source": [
    "!du -sh dynamic_quantization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxHnMAt5fZpT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "66b4d720ab404285bb69e89cba934fc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_22409a1cd60d4a9383a9b3fbd374811c",
       "IPY_MODEL_3d38f9770aa54ad3b4601260643cbc71",
       "IPY_MODEL_309ab64a267847119dbbf799bdba447c"
      ],
      "layout": "IPY_MODEL_ae2b8f28b3974930a3712ed9eb57134d"
     }
    },
    "22409a1cd60d4a9383a9b3fbd374811c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7bcdae127f641d4a1a24d7dc30202d1",
      "placeholder": "​",
      "style": "IPY_MODEL_55e7a12c4ffa4f3dbe19bf215bcc0988",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "3d38f9770aa54ad3b4601260643cbc71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5ad347f0d6d47788baddbd2b4445ff8",
      "max": 694,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4561aad7ee2345a1b2cc251ec48ce0f4",
      "value": 694
     }
    },
    "309ab64a267847119dbbf799bdba447c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65398f401c3744c6b1e966bbd0e2df03",
      "placeholder": "​",
      "style": "IPY_MODEL_1d6326a77fcc48afb1b4c0e0b5835fc7",
      "value": " 694/694 [00:00&lt;00:00, 25.7kB/s]"
     }
    },
    "ae2b8f28b3974930a3712ed9eb57134d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7bcdae127f641d4a1a24d7dc30202d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55e7a12c4ffa4f3dbe19bf215bcc0988": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5ad347f0d6d47788baddbd2b4445ff8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4561aad7ee2345a1b2cc251ec48ce0f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65398f401c3744c6b1e966bbd0e2df03": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d6326a77fcc48afb1b4c0e0b5835fc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58914e1d600c4c0596caae9c5551919b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53015ea7396146868a3711557116a1b6",
       "IPY_MODEL_d6ee4d366725466b81574e2a6c3e9594",
       "IPY_MODEL_f741d07cfe5d47bf846a9d0a13f0fcde"
      ],
      "layout": "IPY_MODEL_0c07640adbf04476aaaf8c49f432bd17"
     }
    },
    "53015ea7396146868a3711557116a1b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efca087f19214f10b9e12c6c67668c39",
      "placeholder": "​",
      "style": "IPY_MODEL_a8bd11df2df04571b4bac9ea9e2666d4",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "d6ee4d366725466b81574e2a6c3e9594": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d09fd22b974444e7938785f845f5463a",
      "max": 597257159,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_56ab5284239e4acdaedfb020efa93166",
      "value": 597257159
     }
    },
    "f741d07cfe5d47bf846a9d0a13f0fcde": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c60ec5df7e944201849b7dc91901d4d9",
      "placeholder": "​",
      "style": "IPY_MODEL_f8c3f6f1b08e42af95ac5df813103911",
      "value": " 597M/597M [00:02&lt;00:00, 255MB/s]"
     }
    },
    "0c07640adbf04476aaaf8c49f432bd17": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efca087f19214f10b9e12c6c67668c39": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8bd11df2df04571b4bac9ea9e2666d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d09fd22b974444e7938785f845f5463a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56ab5284239e4acdaedfb020efa93166": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c60ec5df7e944201849b7dc91901d4d9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8c3f6f1b08e42af95ac5df813103911": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}